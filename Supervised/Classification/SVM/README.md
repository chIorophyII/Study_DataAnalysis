# SVM(Support Vector Machine)
### 정의 : 입력 데이터(저차원)를 고차원 공간으로 변환하고 고차원 공간에서 선형으로 분리할 수 있는 초평면 또는 최적의 선형 결정 경계를 찾는 알고리즘
> - 분류의 경우, 클래스(양품/불량)가 다른 데이터들을 가장 큰 margin으로 분리하는 선 또는 면을 찾음(결정 경계, 분리 초평면)   
단, 비확률적 이진 선형 분류 모델  
> - 예측의 경우, 마진 안에 최대한 많은 샘플을 포함하는 것이 목적  
> - 최대 마진을 가지는 선형 판별에 기초하며, 속성들 간 의존성은 고려하지 않음

### 활용
> * 거래량과 시/종가 활용한 주가 예측
> * 이미지 분류(손글씨 분류 등) : 높은 정확도를 보임
> * 유전자 분류 등

### 장단점
> 장점
>    > * 선형/비선형 구조의 다양한 분류/예측 문제 적용 가능
>    > * 대체로 다른 모델보다 우수한 분류/ 예측 결과를 보임(높은 정확도)  

> 단점
>    > * 결과 해석 즉, 분류 조건에 대한 정보 제공이 미흡  
>    > * 데이터 내부 구조가 선형적으로 구분될 수 있어야 함  
>    > * 데이터 단위의 영향이 커서 사전작업 필요

### 종류 : 선형 분류 SVM / 비선형 분류 SVM

# 선형 SVM
### * Margin : 두 데이터 군과 결정 경계가 떨어져 있는 정도
> Hard margin
>    > * 모든 데이터를 margin 경계 밖으로 분류(엄격한 분류) -> margin 폭이 좁아짐
>    > * 데이터 내부 구조가 선형적으로 구분될 수 있어야 적용 가능
>    > * 이상치에 민감해 때로는 분류가 불가능할 수 있음

> Soft margin
>    > * margin을 크게 하거나 일정 수준의 오류를 허용하는 분류 -> margin 폭이 넓어짐
>    > * C와 gamma 조정 또는 SVR에서는 추가적으로 epsilon 조정

### * Support Vector(지지 벡터) : support vercor들이 결정 경계 형성에 영향을 줌(결정 경계를 지지)
### * 알고리즘
> Hyperplnae : 

### * Cost (비용, C) : 이상치가 포함된 경우 완벽하게 분리할 수 없어 일정 수준의 오류를 허용(비용)
> 얼마나 많은 데이터를 다른 클래스에 놓이는 것(오류)을 허용하는 지를 결정  
> * C가 작을수록(이상치 포함 가능성이 높은 경우) 오류를 많이 허용, 과소적합  
> * C가 클수록 오류를 적게 허용, 과대적합

### * 참조: epsilon(SVR에 적용, SVC는 해당되지 않음) : 마진을 크게 해 마진 안으로 데이터를 최대한 많이 들어가도록 학습하는데 허용 마진 폭
> * epsilon이 증가하면 마진이 커지고 영역 안의 데이터가 증가해 smoothing 효과가 커짐  
> * epsilon이 작을수록 영역 안의 데이터가 감소해 smoothing 효과가 줄어들어 과대 적합 경향이 생김

# 비선형 SVM
### : kernel(커널)기법을 활용해 주어진 데이터를 고차원 공간으로 변환. 그러면 원래 데이터에 없던 선형의 결정 경계면 탐색 가능
- 2차원에서 분류 불가능 -> 3차원으로 사상 -> 다시 2차원으로 매핑 -> 원 모양의 결정경계

### * kernel 종류
> rbf(radial basis function) : 일반적으로 성능이 좋아 많이 사용됨  
> linear : 선형  
> poly : 다항  
> sigmoid : sigmoid  

### * gamma : kernel 최적화를 도와주는 파라미터로 하나의 데이터가 동일한 클래스로 분류되게 하려는 영향력의 거리
> 결정 경계의 곡률 조정  
> Gaussian 함수의 표준편차와 관련(반대 방향)  
> * gamma가 작을수록 1개 데이터의 영향력 거리가 커짐  
> * gamma가 클수록 1개 데이터의 영향력 거리가 짧아짐. 구불구불한 모양

### * C와 gamma 상호관계
> C, gamma 최적 값 탐색이 중요  
> * C, gamma가 커질수록 모델 복잡도는 증가  
> * C, gamma가 작아질수록 모델 복잡도는 낮아짐  

> Grid Search로 최적값 탐색

### * SVM 분류 모델 생성 : SVC
sklearn.svm.SVC(kernel = "rbf", degree = 3, gamma = "auto_deprecated", C = 1.0, random_state = None, ...)

> kernel : 커널 형태 지정, default(rbf)
>    > rbf : (radial basis function)  
>    > linear : 선형  
>    > poly : 다항  
>    > sigmoid : sigmoid  

> * degree : 커널 형태 = poly 지정 시 다항 차수 (default : 3)  
> * gamma : kernel = rbf, poly, sigmoid 지정 시 kernel 계수 (default : auto = 1 / (# of 설명변수)  
> * C(대문자) : error term의 penalty 계수, default(1.0)  
> * random_state : 초기 자료 선택 기준, 값에 따라 선택되는 데이터가 달라짐, default(None)  
