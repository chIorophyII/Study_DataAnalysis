{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e88893",
   "metadata": {},
   "source": [
    "# 다중 회귀분석\n",
    "## 정의\n",
    "### : 목표변수와 다수(2개 이상)의 설명변수와의 선형관계를 분석하는 (확률적) 모델\n",
    "\n",
    "## 모델\n",
    "### : 회귀계수(=기울기)는 최소자승법(Least Squres Method)을 활용\n",
    "$$ y_i = \\beta_0 + \\beta_1x_{1i} + ... + \\beta_kx_{ki} + \\epsilon$$\n",
    "($i = 1,...,n,   e_i~N(0,\\sigma^2)$)  \n",
    "$\\beta_0$ : 절편으로서 모델이 $y$축을 통과하는 점  \n",
    "$\\beta_j$ : $j$번째 설명변수 $x_j$의 회귀계수로 다른 모든 설명변수 값을 고정한 상태에서 $x_j$가 1단위 증가함에 따른 $y$의 변화량  \n",
    "$\\epsilon$ : 모델의 잔차\n",
    "\n",
    "### 오차항의 필요조건\n",
    "> - 오차항의 확률분포는 정규분포를 따름  \n",
    "> - 오차항은 평균이 0이고 표준편차가 $\\sigma$  \n",
    "> - $\\epsilon ~ N(0,\\sigma^2)$로 표현  \n",
    "> - 오차항은 독립\n",
    "\n",
    "## 분석절차\n",
    "1. 경향성 확인 \n",
    "> - 변수(목표변수 vs 설명변수) 간 산점도 분석을 통한 패턴, 경향성 확인\n",
    "> - 변수(목표변수 vs 설명변수) 간 상관관계 분석\n",
    "2. 모델의 적합성 확인 \n",
    "> - 분산분석(ANOVA)을 통한 모델의 적합성 확인\n",
    "> - 결정계수($R^2$) 확인을 통한 모델의 설명력 확인\n",
    "3. 회귀계수 계산 및 확인\n",
    "> **선택된 모델의 회귀계수 계산 및 유의성 확인**  \n",
    "> - $t$-검정을 통한 회귀계수의 유의성 확인  \n",
    "> - 설명변수 간 다중공선성 확인 및 적절한 조치  \n",
    "> - 목표변수에 영향을 주는 설명변수 선택 및 해석\n",
    "4. 잔차(오차) 분석\n",
    "> **잔차의 기본 가정 확인**\n",
    "> - 잔차의 정규성, 등분산성, 독립성 등 확인\n",
    "5. 모델 선정\n",
    "> **모델의 적합성, 오차의 가정 만족 여부를 확인하고 최종 모델 선정**\n",
    "\n",
    "### 다중공선성\n",
    "#### 정의 : 설명변수 간 선형관계(높은 상관관계)가 높아 발생하는 문제\n",
    "> - 이로 인해 최소자승법으로 추정한 모델의 회귀계수에 대한 신뢰성이 떨어짐  \n",
    "> - 설명변수의 회귀계수 및 유의성 판단에 오류가 발생할 수 있음\n",
    "\n",
    "#### 원인\n",
    "> - 설명변수들 간 높은 (선형)상관관계  \n",
    "> - 편향된 표본 데이터 추출 -> 표본의 크기를 늘리거나 반복 실행\n",
    "\n",
    "#### 진단\n",
    "> - 모델 결정계수는 높지만 설명변수의 회귀계수 P값이 높아 유의하지 않을 수 있음  \n",
    "> - 산점도 또는 상관계수를 확인해 설명변수 간 선형관계 파악  \n",
    "> - 분산팽창계수(Variation Inflation Factor; VIF) 이용\n",
    ">    > - $VIF_j = \\frac{1}{1-R_J^2}$  \n",
    ">    > - 분산팽창계수 : 10보다 크면 다중공선성 존재\n",
    ">    > - $R_j^2$ : 설명변수 $x_j$를 목표변수, 나머지를 설명변수로 이용한 회귀모델의 설명력\n",
    "\n",
    "#### 처리\n",
    "> - 상관관계가 높은 설명변수 중 (목표변수와 상관관계가 낮은) 일부 변수를 제거  \n",
    "> - 변수를 변환하거나 새로운 데이터 추가  \n",
    "> - 주성분 분석을 이용해 설명변수 간 선형관계로 생성된 주성분 변수 이용\n",
    "\n",
    "### 변수선택법\n",
    "#### 후진제거법(Backward Elimination)\n",
    "> - 모든 설명변수들을 포함한 모형에서 시작해 설명력이 가장 작은 변수부터 순차적으로 제거하면서 더 이상 제거할 변수가 없다고 판단될 때 변수의 선택을 중단하는 방법  \n",
    "> - 단점 : 제거된 변수는 추가할 수 없음\n",
    "\n",
    "#### 전진선택법(Forward Selection)\n",
    "> - 상수항에서 출발해 설명력이 큰 변수부터 선택해 모형에 포함시키면서 더 이상 추가할 의미가 없다고 판단될 때 변수의 선택을 중단하는 방법  \n",
    "> - 단점 : 회귀식에 추가된 변수는 제거할 수 없음  \n",
    "> - Python에서 직접 제공되는 패키지 없음(사용자 개발 패키지 사용 가능)\n",
    "\n",
    "#### 단계적 선택법(Stepwise)\n",
    "> - 전진선택법과 후진선택법을 조합해 단점을 보완  \n",
    ">    > : 단점 - 전진선택에 의해 포함된 변수는 제거될 수 없으며, 후진 선택에 의해 제거된 변수는 다시 포함될 수 없음  \n",
    "> 전진선택법에 따라 중요 변수가 추가되고 후진선택법에 따라 중요하지 않은 변수 제거(반복적)  \n",
    "> Python에서 직접 제공되는 패키지 없음(사용자 개발 패키지 사용 가능)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
